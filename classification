# %%
import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.datasets as dsets
import matplotlib.pylab as plt
import numpy as np 


# %%
###Data###
train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())
validation_dataset = dsets.MNIST(root='./data', download=True, transform=transforms.ToTensor())


# %%
def show_data(data_sample):
    plt.imshow(data_sample[0].numpy().reshape(28, 28), cmap='gray')
    plt.title('y = ' + str(data_sample[1]))

# %%
print("The image: ", show_data(train_dataset[3]))

# %%
show_data(train_dataset[2])

# %%
#Define softmax classifier class
class SoftMax(nn.Module):
    def __init__(self, input_size, output_size):
        super(SoftMax, self).__init__()
        self.linear = nn.Linear(input_size, output_size)
    def forward(self, x):
        z = self.linear(x)
        return z

# %%
#visualize data
imput_dim = 28 * 28
output_dim = 10 


# %%
model = SoftMax(imput_dim, output_dim)
print(model)

# %%
# Plot Param
def PlotParameters(model): 
    W = model.state_dict()['linear.weight'].data
    w_min = W.min().item()
    w_max = W.max().item()
    fig, axes = plt.subplots(2, 5)
    fig.subplots_adjust(hspace=0.01, wspace=0.1)
    for i, ax in enumerate(axes.flat):
        if i < 10:
            
            ax.set_xlabel("class: {0}".format(i))

            ax.imshow(W[i, :].view(28, 28), vmin=w_min, vmax=w_max, cmap='seismic')

            ax.set_xticks([])
            ax.set_yticks([])

    plt.show()

# %%
PlotParameters(model)

# %%
#Define the learning rate, optimizer, criterion and data loader
learning_rate = 0.1
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)
criterion = nn.CrossEntropyLoss()
train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100)
validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000)

# %%
# Train
n_epochs = 10
loss_list = [ ]
accuracy_list = []
N_test = len(validation_dataset)


def train_model(n_epochs):
    for epoch in range(n_epochs):
        for x, y in train_loader:
            z = model(x.view(-1, 28*28))
            loss = criterion(z, y)
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
        
        correct = 0
        for x_test, y_test in validation_loader:
            z = model(x_test.view(-1, 28*28))
            _, yhat = torch.max(z.data, 1)
            correct += (yhat == y_test).sum().item()
        accuracy = correct / N_test 
        loss_list.append(loss.data)
        accuracy_list.append(accuracy)  
        
train_model(n_epochs)         

# %%



